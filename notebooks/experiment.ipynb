{"cells":[{"cell_type":"markdown","metadata":{},"outputs":[],"source":["# SSBR Baseline"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":"%load_ext autoreload\n%autoreload 2"},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":"from ssbr.datasets.ircad import IrcadData\nfrom ssbr.datasets.utils import DicomVolumeStore, stack_sampler, SSBRDataset\nfrom ssbr.datasets.ops import grey2rgb, resize, rescale, image2np\nfrom pathlib import Path\nimport numpy as np\nimport os\nimport h5py\nfrom ssbr.model import ssbr_model\nfrom keras.callbacks import ModelCheckpoint"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Data sources\n","\n","### Dataset\n","\n","We use IRCAD's liver dataset for training a baseline model. This dataset is composed of 20 abdominal CT scans and a number of segmented organs, mainly the liver.\n","\n","The `IrcadData` is a utility class which downloads and extracts the data. It also provides a mapping between volume_ids and their corresponding dicom folder."]},{"cell_type":"code","execution_count":62,"metadata":{"scrolled":true},"outputs":[],"source":"ircad_folder = Path('../data/ircad')\nircad = IrcadData(ircad_folder)\n\nfor k, v in ircad.items():\n    print(f'{k} -{v}')"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["\n","### Data generator\n","\n","The data source for the SSBR model must provide a 5 dimensional array :\n","\n","`[BATCH_SIZE, NUM_SLICES, WIDTH, HEIGHT, CHANNEL]`\n","\n","A sample in this case is a stack of equidistant slices sampled inside the dicom volume. Each image is a 2 dimensional, 3 channel array.\n","\n","When loading the volumes, a series of volumes transformations are applied before sampling equidistant slices. The transfomed volumes are cached in an HDF5 file to only load slices from disk when needed.\n","\n","The DicomVolumeStore class provides a mapping between volume_ids and transformed volume (the HDF5 cache interface). This store also manages the split ratio for training and validation.\n","\n","Finally the SSBRDataset is a generator that yields batches of image stacks."]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":"BATCH_SIZE = 4 # The number of image stacks\nNUM_SLICES = 8 # The number of equidistant images per stacks\n\nvolume_transforms = [\n    resize((64, 64)),\n    image2np,\n    rescale(low=-300, high=700, scale=255, dtype=np.uint8),\n    grey2rgb,\n]\n\n\ncache = h5py.File(str(ircad_folder / 'ircad.h5'), 'a')\nvolumes = DicomVolumeStore(ircad, transforms=volume_transforms, cache=cache)\ndataset = SSBRDataset(volumes=volumes, split=0.2)\ndatagen_train = dataset.train(batch_size=BATCH_SIZE, num_slices=NUM_SLICES)\ndatagen_valid = dataset.valid(batch_size=BATCH_SIZE, num_slices=NUM_SLICES)\n\n# Since this training dataset is small, we build the cache right away\nvolumes.build_cache()"},{"cell_type":"code","execution_count":71,"metadata":{"scrolled":false},"outputs":[],"source":"%matplotlib notebook\nfrom ipywidgets import interact\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\n\nbatch, _ = next(datagen_train)\nstack = batch[0]\n\nfig = plt.figure()\nax = plt.imshow(stack[0])\n\nslider = widgets.IntSlider(min=0, max=NUM_SLICES-1, step=1, value=0)\ndef update(sli = slider):\n    ax.set_data(stack[sli])\n\ninteract(update)\n"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Model\n","\n","The model definition provided by `ssbr_model` provides two entrypoints. The first one, `m`, will be the model for the training procedure which requires an input slice stack. The second one, `score_extractor`, will be used at prediction time for evaluating the score for individual slices."]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":"config = {}\nMODEL = '../data/model.h5'\nm, score_extractor = ssbr_model(lr=config.get('lr', 0.0001),\n                                batch_size=BATCH_SIZE,\n                                num_slices=NUM_SLICES,\n                                alpha=config.get('alpha', 0.5))"},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":"os.makedirs(os.path.dirname(MODEL), exist_ok=True)\nmcp = ModelCheckpoint(filepath=MODEL,\n                      monitor='val_loss',\n                      verbose=1,\n                      save_best_only=True)"},{"cell_type":"code","execution_count":85,"metadata":{"scrolled":true},"outputs":[],"source":"hist = m.fit_generator(generator=datagen_train,\n                       steps_per_epoch=50,\n                       epochs=30,\n                       callbacks=[mcp],\n                       validation_data=datagen_valid,\n                       validation_steps=30)"},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":"# Plot losses\nfig = plt.figure()\nlabels = []\nfor k, v in hist.history.items():\n    labels.append(k)\n    plt.plot(v)\nplt.legend(labels)\nplt.show()"},{"cell_type":"markdown","metadata":{},"outputs":[],"source":["## Model evaluation\n"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":"from ssbr.datasets.utils import batcher\n\nm.load_weights(MODEL)\n\nresults = {}\nfor vid in volumes:\n    print(f'Computing results for volume {vid}')\n    vol = volumes[vid]\n    scores= []\n    for batch in batcher(vol, 10):\n        sco = score_extractor.predict_on_batch(batch)\n        scores.extend(sco)\n    results[vid] = np.asarray(scores)\n"},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":"import matplotlib\n%matplotlib inline"},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":"import matplotlib.pyplot as plt\nfor vid, val in results.items():\n    plt.plot(val)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}